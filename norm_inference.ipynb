{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(\"nlstruct\")\n",
    "logger.setLevel(logging.DEBUG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0,'/home/ytaille/deep_multilingual_normalization')\n",
    "\n",
    "from nlstruct.utils import torch_clone\n",
    "from nlstruct.utils import torch_global as tg\n",
    "from deep_multilingual_normalization.preprocess import preprocess, load_quaero\n",
    "from deep_multilingual_normalization.train import train_step1, train_step2, clear\n",
    "from deep_multilingual_normalization.eval import compute_scores, predict\n",
    "\n",
    "from transformers import AutoModel\n",
    "from deep_multilingual_normalization.model import Classifier, FastClusteredIPSearch\n",
    "\n",
    "from notebook_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CUDA devices: 1\n",
      "Current device: cuda:0\n",
      "Using cache /home/ytaille/data/cache/preprocess_training_data/579ec808c912b49f\n",
      "Loading /home/ytaille/data/cache/preprocess_training_data/579ec808c912b49f/output.pkl... \n",
      "Using cache /home/ytaille/data/cache/ncbi_raw_files/4d8c0405832b0f7e\n",
      "Quaero mentions: 5259\n",
      "Total deduplicated synonyms: 18123\n",
      "Total deduplicated labels: 13051\n",
      "Quaero mentions: 16283\n",
      "Normalized split, with given vocabulary and no unk\n",
      "Normalized label, with given vocabulary and no unk\n",
      "Normalized quaero_source, with given vocabulary and no unk\n",
      "Normalized token, with given vocabulary and no unk\n",
      "Normalized group, with given vocabulary and no unk\n",
      "Normalized source, with given vocabulary and no unk\n",
      "Using cache /home/ytaille/data/cache/norm/paper/train_step1/34ef6f8317449a23\n",
      "Loading /home/ytaille/data/cache/norm/paper/train_step1/34ef6f8317449a23/history.yaml... \n",
      "epoch | train_loss | train_acc | val_loss | val_acc | val_map | acc_emea | acc_medline |        lr |   norm |     step |    dur(s)\n",
      "    1 |     \u001b[32m8.1437\u001b[0m |    \u001b[32m0.1521\u001b[0m |      \u001b[32mnan\u001b[0m |  \u001b[32m0.0000\u001b[0m |  \u001b[32m0.0000\u001b[0m |   \u001b[32m0.0000\u001b[0m |      \u001b[32m0.0000\u001b[0m | 8.000e-03 |   2.18 |      142 |   16.8652\n",
      "    2 |     \u001b[32m5.5243\u001b[0m |    \u001b[32m0.2556\u001b[0m |      \u001b[31mnan\u001b[0m |  \u001b[31m0.0000\u001b[0m |  \u001b[31m0.0000\u001b[0m |   \u001b[31m0.0000\u001b[0m |      \u001b[31m0.0000\u001b[0m | 7.704e-03 |   2.44 |      284 |   17.1078\n",
      "    3 |     \u001b[32m3.3696\u001b[0m |    \u001b[32m0.4246\u001b[0m |      \u001b[31mnan\u001b[0m |  \u001b[31m0.0000\u001b[0m |  \u001b[31m0.0000\u001b[0m |   \u001b[31m0.0000\u001b[0m |      \u001b[31m0.0000\u001b[0m | 7.111e-03 |   2.51 |      426 |   16.2543\n",
      "    4 |     \u001b[32m1.6156\u001b[0m |    \u001b[32m0.7375\u001b[0m |      \u001b[31mnan\u001b[0m |  \u001b[31m0.0000\u001b[0m |  \u001b[31m0.0000\u001b[0m |   \u001b[31m0.0000\u001b[0m |      \u001b[31m0.0000\u001b[0m | 6.519e-03 |   2.55 |      568 |   16.2651\n",
      "    5 |     \u001b[32m0.7503\u001b[0m |    \u001b[32m0.8850\u001b[0m |      \u001b[31mnan\u001b[0m |  \u001b[31m0.0000\u001b[0m |  \u001b[31m0.0000\u001b[0m |   \u001b[31m0.0000\u001b[0m |      \u001b[31m0.0000\u001b[0m | 5.926e-03 |   2.56 |      710 |   16.3029\n",
      "    6 |     \u001b[32m0.4094\u001b[0m |    \u001b[32m0.9529\u001b[0m |      \u001b[31mnan\u001b[0m |  \u001b[31m0.0000\u001b[0m |  \u001b[31m0.0000\u001b[0m |   \u001b[31m0.0000\u001b[0m |      \u001b[31m0.0000\u001b[0m | 5.333e-03 |   2.56 |      852 |   16.2786\n",
      "    7 |     \u001b[32m0.2790\u001b[0m |    \u001b[32m0.9756\u001b[0m |      \u001b[31mnan\u001b[0m |  \u001b[31m0.0000\u001b[0m |  \u001b[31m0.0000\u001b[0m |   \u001b[31m0.0000\u001b[0m |      \u001b[31m0.0000\u001b[0m | 4.741e-03 |   2.55 |      994 |   16.3123\n",
      "    8 |     \u001b[32m0.2130\u001b[0m |    \u001b[32m0.9826\u001b[0m |      \u001b[31mnan\u001b[0m |  \u001b[31m0.0000\u001b[0m |  \u001b[31m0.0000\u001b[0m |   \u001b[31m0.0000\u001b[0m |      \u001b[31m0.0000\u001b[0m | 4.148e-03 |   2.55 |     1136 |   16.3313\n",
      "    9 |     \u001b[32m0.1747\u001b[0m |    \u001b[32m0.9873\u001b[0m |      \u001b[31mnan\u001b[0m |  \u001b[31m0.0000\u001b[0m |  \u001b[31m0.0000\u001b[0m |   \u001b[31m0.0000\u001b[0m |      \u001b[31m0.0000\u001b[0m | 3.556e-03 |   2.54 |     1278 |   16.3350\n",
      "   10 |     \u001b[32m0.1504\u001b[0m |    \u001b[32m0.9891\u001b[0m |      \u001b[31mnan\u001b[0m |  \u001b[31m0.0000\u001b[0m |  \u001b[31m0.0000\u001b[0m |   \u001b[31m0.0000\u001b[0m |      \u001b[31m0.0000\u001b[0m | 2.963e-03 |   2.54 |     1420 |   16.4198\n",
      "   11 |     \u001b[32m0.1318\u001b[0m |    \u001b[32m0.9909\u001b[0m |      \u001b[31mnan\u001b[0m |  \u001b[31m0.0000\u001b[0m |  \u001b[31m0.0000\u001b[0m |   \u001b[31m0.0000\u001b[0m |      \u001b[31m0.0000\u001b[0m | 2.370e-03 |   2.54 |     1562 |   17.1435\n",
      "   12 |     \u001b[32m0.1229\u001b[0m |    \u001b[32m0.9912\u001b[0m |      \u001b[31mnan\u001b[0m |  \u001b[31m0.0000\u001b[0m |  \u001b[31m0.0000\u001b[0m |   \u001b[31m0.0000\u001b[0m |      \u001b[31m0.0000\u001b[0m | 1.778e-03 |   2.53 |     1704 |   16.3537\n",
      "   13 |     \u001b[32m0.1152\u001b[0m |    \u001b[32m0.9918\u001b[0m |      \u001b[31mnan\u001b[0m |  \u001b[31m0.0000\u001b[0m |  \u001b[31m0.0000\u001b[0m |   \u001b[31m0.0000\u001b[0m |      \u001b[31m0.0000\u001b[0m | 1.185e-03 |   2.53 |     1846 |   16.3633\n",
      "   14 |     \u001b[32m0.1069\u001b[0m |    \u001b[32m0.9927\u001b[0m |      \u001b[31mnan\u001b[0m |  \u001b[31m0.0000\u001b[0m |  \u001b[31m0.0000\u001b[0m |   \u001b[31m0.0000\u001b[0m |      \u001b[31m0.0000\u001b[0m | 5.926e-04 |   2.53 |     1988 |   16.4526\n",
      "   15 |     \u001b[32m0.1028\u001b[0m |    \u001b[32m0.9928\u001b[0m |      \u001b[31mnan\u001b[0m |  \u001b[31m0.0000\u001b[0m |  \u001b[31m0.0000\u001b[0m |   \u001b[31m0.0000\u001b[0m |      \u001b[31m0.0000\u001b[0m | 0.000e+00 |   2.53 |     2130 |   17.1916\n",
      "Loading /home/ytaille/data/cache/norm/paper/train_step1/34ef6f8317449a23/checkpoint-15.pt... \n",
      "Model restored to its best self.state: 15\n"
     ]
    }
   ],
   "source": [
    "from create_classifiers import create_classifiers\n",
    "\n",
    "classifier, classifier2 = create_classifiers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ytaille/.conda/envs/deep_mult_norm/lib/python3.7/site-packages/nlstruct/text/chunking/huggingface.py:11: FutureWarning: doc_id_col is not used anymore in the huggingface_tokenize function\n",
      "  warnings.warn(\"doc_id_col is not used anymore in the huggingface_tokenize function\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CUDA devices: 1\n",
      "Current device: cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'forward'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ec59aac2455f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_sort_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"token_mask\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mwith_tqdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmininterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10.\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 res = classifier2.forward(\n\u001b[0m\u001b[1;32m     34\u001b[0m                     \u001b[0mtokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"token\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"token_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'forward'"
     ]
    }
   ],
   "source": [
    "bert_name = \"bert-base-multilingual-uncased\"\n",
    "\n",
    "dataset = load_from_brat(\"/home/ytaille/data/tmp/ws_inputs\")\n",
    "\n",
    "docs, sentences, tokens, deltas, vocs = preprocess(\n",
    "    dataset=dataset,\n",
    "    max_sentence_length=120,\n",
    "    bert_name=bert_name,\n",
    "    vocabularies=None,\n",
    ")\n",
    "\n",
    "prep = Dataset(\n",
    "    sentences=sentences,\n",
    "    tokens=tokens,\n",
    "    deltas=deltas,\n",
    ")\n",
    "\n",
    "batcher, encoded, ids = make_batcher(docs, sentences, tokens)\n",
    "\n",
    "batch_size = 32\n",
    "with_tqdm = True\n",
    "with_groups = False\n",
    "topk = 1\n",
    "save_embeds = False\n",
    "\n",
    "tg.set_device('cuda:0')\n",
    "device = tg.device\n",
    "\n",
    "with evaluating(classifier):  # eval mode: no dropout, frozen batch norm, etc\n",
    "    with torch.no_grad():  # no gradients -> faster\n",
    "        with tqdm(batcher.dataloader(batch_size=batch_size, device=device, sparse_sort_on=\"token_mask\"), disable=not with_tqdm, mininterval=10.) as bar:\n",
    "            for batch in bar:\n",
    "                res = classifier2.forward(\n",
    "                    tokens=batch[\"token\"],\n",
    "                    mask=batch[\"token_mask\"],\n",
    "                    groups=batch[\"group\"] if with_groups else None,\n",
    "                    return_scores=topk > 0.1,\n",
    "                    return_embeds=save_embeds,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_probs = res['scores'].topk(dim=-1, k=topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([[8.3149],\n",
       "        [9.0723],\n",
       "        [7.5563],\n",
       "        [8.5602]], device='cuda:0'),\n",
       "indices=tensor([[528324],\n",
       "        [488454],\n",
       "        [ 98788],\n",
       "        [192771]], device='cuda:0'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.3149],\n",
       "        [9.0723],\n",
       "        [7.5563],\n",
       "        [8.5602]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_probs.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_mult_norm",
   "language": "python",
   "name": "deep_mult_norm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
